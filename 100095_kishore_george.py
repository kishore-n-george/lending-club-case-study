# -*- coding: utf-8 -*-
"""LendingClub.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16masLxAiBTUwRm14ASiR0U5ti05vsnTQ
"""

# !pip show matplotlib
# upgrading matplotlib to 3.5.3 for better plots
# !pip install matplotlib --upgrade
# plot.bar_label(hplot.containers[0]) <- this works only with 3.4 version of matplotlib

"""Loading the Dataset"""

# load the dataset
import pandas as pd;
loan = pd.read_csv("loan.csv");
# check the total entries, missing data in columns, datatypes
# 39717 rows, 111 columns
loan.info(verbose=True, show_counts=True)

"""Data Cleaning"""

# check for duplicate rows based on id
any_duplicates=loan.duplicated(['id']).any()
print(any_duplicates)
# no duplicate records found

# remove empty columns
loan = loan.dropna(axis = 1, how = 'all')
loan.info(verbose=True, show_counts=True)
# sorted(loan.columns)
# Columns reduced from 111 to 57

#drop all the rows with only nan values
loan = loan.dropna(axis = 0, how = 'all')
loan.info()
# no of rows remains 39717

## drop rows where the loan_status='Current'
# indexAge = loan[(loan['loan_status']=='Current') ].index
# loan.drop(indexAge , inplace=True)
## drop rows where loan_status is nan
# loan=loan[loan['loan_status'].notna()]
# print(loan.shape)
## no of rows reduced 38577
## set loan_status -> Fully Paid to 1;;
## set loan_status -> Charged Off to 0;;
# loan['loan_status'].replace({'Fully Paid': 1, 'Charged Off': 0},inplace=True)
# loan['loan_status'].unique()

#drop columns that have high percentage of nan
print(loan.shape)
# keep columns where null percentage is less than 60%
loan = loan.loc[:, loan.isnull().mean() < .6]
# three columns with high percentage of nulls dropped
print(loan.shape)

# drop rows that have high percentage of nan
perc = 60.0 
# calculates minimun number of columns without null value to reach 60%
min_count =  int(((100-perc)/100)*loan.shape[1] + 1)
#atleast 22 columns should be non na
print(min_count)
loan = loan.dropna( axis=0, 
                    thresh=min_count)
loan.shape
# no rows to drop , remains 39717

#drop columns that are not relevant to business problem.
columns_list = ["desc","member_id","url","emp_title","zip_code","tax_liens","policy_code","initial_list_status","installment"]
loan.drop(labels = columns_list, axis =1, inplace=True)
#columns reduced to 45
print(loan.shape)
loan.info()

"""Data Manipulation/Imputation"""

# data cleaning
# check every column
# fix nulls
# derive columns from timestamps
# impute data where required
# columns emp_length has nulls -> impute
print('Before Cleaning')
print(loan['emp_length'].unique())
# extract only the numerical year.
loan['emp_length']=loan['emp_length'].str.extract('(\d+)')
loan['emp_length'].fillna('0',inplace=True)
print('After Cleaning')
print(loan['emp_length'].unique())

# column title has 11 nulls -> impute
print('Before Cleaning')
print(loan['title'].isnull().sum())
loan['title'].fillna('Not Known',inplace=True)
print('After Cleaning')
print(loan['title'].isnull().sum())

# column revol_util has null -> impute
# revol_util -> Revolving line utilization rate, or the amount of credit the borrower is using relative to all available revolving credit.
print('Before Cleaning')
print(loan['revol_util'].isnull().sum())
print(loan['revol_util'].unique())
# extract only the numbers
# loan['revol_util'].str.extract('(\d+.\d+)')
# or remove the '%'
loan['revol_util']=loan['revol_util'].str.rstrip('%')
print('After Cleaning')
print(loan['revol_util'].unique())
# not imputing nulls with 0, mean, median, mode as they will be unrepresentative

# column last_pymnt_d has nulls -> impute
print('Before Cleaning')
print(loan['last_pymnt_d'].isnull().sum())
print(loan['last_pymnt_d'].head(5))
# creating derived columns
# it is a date column with mon-yy format
# split these into two columns
# last_pymnt_d_mon & last_pymnt_d_year
loan['last_pymnt_d']=pd.to_datetime(loan['last_pymnt_d'], format='%b-%y')
loan['last_pymnt_d_year']=loan['last_pymnt_d'].dt.year
loan['last_pymnt_d_mon']=loan['last_pymnt_d'].dt.month
# not imputing nulls.
print('After Cleaning')
print(loan['last_pymnt_d'].isnull().sum())
print(loan['last_pymnt_d'].head(5))
print(loan['last_pymnt_d_year'].head(5))
print(loan['last_pymnt_d_mon'].head(5))
loan.shape
# added two columns

# column last_credit_pull_d  has nulls -> impute
print('Before Cleaning')
print(loan['last_credit_pull_d'].isnull().sum())
print(loan['last_credit_pull_d'].head(5))
# creating derived columns
# it is a date column with mon-yy format
# split these into two columns
# last_credit_pull_d_mon & last_credit_pull_d_year
loan['last_credit_pull_d']=pd.to_datetime(loan['last_credit_pull_d'], format='%b-%y')
loan['last_credit_pull_d_year']=loan['last_credit_pull_d'].dt.year
loan['last_credit_pull_d_mon']=loan['last_credit_pull_d'].dt.month
# not imputing nulls.
print('After Cleaning')
print(loan['last_credit_pull_d'].isnull().sum())
print(loan['last_credit_pull_d'].head(5))
print(loan['last_credit_pull_d_year'].head(5))
print(loan['last_credit_pull_d_mon'].head(5))
loan.shape
# added two columns

# column collections_12_mths_ex_med has nulls -> impute
print('Before Cleaning')
print(loan['collections_12_mths_ex_med'].isnull().sum())
print(loan['collections_12_mths_ex_med'].unique())
# has only 0 and nan , safe to impute nan with 0
loan['collections_12_mths_ex_med'].fillna(0,inplace=True)
print('After Cleaning')
print(loan['collections_12_mths_ex_med'].unique())
print(loan['collections_12_mths_ex_med'].isnull().sum())

# column chargeoff_within_12_mths has nulls -> impute
print('Before Cleaning')
print(loan['chargeoff_within_12_mths'].isnull().sum())
print(loan['chargeoff_within_12_mths'].unique())
# has only 0 and nan , safe to impute nan with 0
loan['chargeoff_within_12_mths'].fillna(0,inplace=True)
print('After Cleaning')
print(loan['chargeoff_within_12_mths'].unique())
print(loan['chargeoff_within_12_mths'].isnull().sum())

# column pub_rec_bankruptcies has nulls -> impute
# pub_rec_bankruptcies -> Number of public record bankruptcies
print('Before Cleaning')
print(loan['pub_rec_bankruptcies'].isnull().sum())
print(loan['pub_rec_bankruptcies'].unique())
loan['pub_rec_bankruptcies'].fillna('Not Known',inplace=True)
print('After Cleaning')
print(loan['pub_rec_bankruptcies'].unique())
print(loan['pub_rec_bankruptcies'].isnull().sum())

# column issue_d can be used to derive two more columns
print('Before extraction')
print(loan['issue_d'].head(10))
# creating derived columns
# it is a date column with mon-yy format
# split these into two columns
# issue_d_mon & issue_d_year
loan['issue_d']=pd.to_datetime(loan['issue_d'], format='%b-%y')
loan['issue_d_year']=loan['issue_d'].dt.year
loan['issue_d_mon']=loan['issue_d'].dt.month
# not imputing nulls.
print('After extraction')
print(loan['issue_d'].head(10))
print(loan['issue_d_year'].head(10))
print(loan['issue_d_mon'].head(10))
loan.shape
# added two columns

# column earliest_cr_line is mm-yy format
print('Before extraction')
print(loan['earliest_cr_line'].head(5))
# creating derived columns
# it is a date column with mon-yy format
# split these into two columns
# earliest_cr_line_mon & earliest_cr_line_year
loan['earliest_cr_line']=pd.to_datetime(loan['earliest_cr_line'], format='%b-%y')
loan['earliest_cr_line_year']=loan['earliest_cr_line'].dt.year
loan['earliest_cr_line_mon']=loan['earliest_cr_line'].dt.month
# not imputing nulls.
print('After extraction')
print(loan['earliest_cr_line'].head(10))
print(loan['earliest_cr_line_year'].head(10))
print(loan['earliest_cr_line_mon'].head(10))
loan.shape

# column int_rate has %, it can be removed
print('Before Cleaning')
print(loan['int_rate'].head(5))
loan['int_rate'] = loan['int_rate'].str.rstrip('%')
print('After Cleaning')
print(loan['int_rate'].head(5))

# column term can be cleaned for analysis
print('Before Cleaning')
print(loan['term'].unique())
loan['term'] = loan['term'].str.extract('(\d+)')
print('After Cleaning')
print(loan['term'].unique())

"""Converting Datatypes of Columns"""

# checking column types to check if some columns can be converted to numeric/float help with analysis
print('Before Conversion, check dtypes')
# loan.info()
# check these columns and convert to int if possible
# term, int_rate, emp_length, revolv_util
print(loan['term'].head(5))
print(loan['int_rate'].head(5))
print(loan['emp_length'].head(5))
print(loan['revol_util'].head(5))

columns = ['term','int_rate','emp_length','revol_util']
loan[columns] = loan[columns].apply(pd.to_numeric)
print('After Conversion, check dtypes')
print(loan['term'].head(5))
print(loan['int_rate'].head(5))
print(loan['emp_length'].head(5))
print(loan['revol_util'].head(5))

"""Check out of the box metrics in a dataframe"""

loan.info()

# decribe the stats of continous variables 
loan.describe()

# Find the correlation
loan.corr()

"""Business driven derived metrics"""

loan['open_acc'].unique()

# Derived columns

# categorise loan amounts into buckets which will help in analysis further in bivariate analysis.
# loan['loan_amnt'].describe()
# using percentile values to create categories
loan['loan_amnt_cat'] = pd.cut(loan['loan_amnt'], [0, 5400, 10000, 15000, 25000, 35000], labels=['0-5400', '5400-10000', '10000-15000', '15000-25000', '25000 +'])
# categorise interest rate into buckets which will help in analysis further in bivariate analysis.
# loan['int_rate'].describe()
# using percentile values to create categories
loan['int_rate_cat'] = pd.cut(loan['int_rate'], [0, 9, 12, 15, 18, 25], labels=['0-9', '9-12', '12-15', '15-18', '18 +'])
# categorise annual income into buckets which will help in analysis further in bivariate analysis.
# using percentile values to create categories
# loan['annual_inc'].describe()
loan['annual_inc_cat'] = pd.cut(loan['annual_inc'], [0,20000, 40000, 60000, 80000, 100000], labels=['0-20000', '20000-40000', '40000-60000', '60000-80000', '80000 +'])
# categorise revol util into buckets which will help in analysis further in bivariate analysis.
loan['revol_util_cat'] = pd.cut(loan['revol_util'], [0,20, 40, 60,80,100], labels=['0-20','20-40', '40-60', '60-80', '80-100'])
# categorise open acc into buckets which will help in analysis further in bivariate analysis.
loan['open_acc_cat'] = pd.cut(loan['revol_util'], [0,10, 20, 30,40,50], labels=['0-10','10-20', '20-30', '30-40', '40+'])

"""**Univariate Analysis**"""

# Univariate analysis
import seaborn as sns #wrapper on matplotlib
import matplotlib.pyplot as plt
# sns.set(rc={'figure.figsize':(15,8),'facecolor':'lightblue'})
sns.set_style("dark")
columns_list_remove = set(())

def draw_custom_hist_plot(df,x,xlabel,ylabel):
  plt.figure(figsize=(15,8),facecolor='lightblue')
  hplot = sns.histplot(df[x])
  hplot.set_title(f'{xlabel} - Hist Plot',fontsize=14,color='black')
  hplot.set_xlabel(xlabel,fontsize=14,color='b')
  hplot.set_ylabel(ylabel,fontsize=14,color='b')
  return hplot

"""Univariate Analysis of Application Type - Categorical Variable"""

draw_custom_hist_plot(loan,'application_type','Application Type','Count')
columns_list_remove.add('application_type')

# Inference: 
# - all the applications are individual applications.

"""Univariate Analysis of Payment Plan - Categorical Variable"""

draw_custom_hist_plot(loan,'pymnt_plan','Payment Plan','Count')
columns_list_remove.add('pymnt_plan')

# Inference: 
# - No application had a payment plan put in place.

"""Univariate Analysis on State - Categorical Variable"""

# shows the state with maximum # of loan applications
draw_custom_hist_plot(loan,'addr_state','State','Count')
# Inference:
# - State CA has the most number of applications

"""Univariate Analysis of Annual Income - Quantitative Variable """

loan['annual_inc'].describe()

def draw_annual_income_plots():
  plt.figure(figsize=(15,10),facecolor='lightblue')
  plt.subplot(2, 2, 1)
  bplot = sns.boxplot(y=loan['annual_inc'])
  bplot.ticklabel_format(style='plain', axis='y')
  bplot.set_title('Annual Income - Box Plot',fontsize=14,color='black')
  bplot.set_ylabel('Annual Income',fontsize=14,color='b')
  plt.subplot(2, 2, 2)
  hplot = sns.histplot(loan['annual_inc'])
  hplot.ticklabel_format(style='plain', axis='x')
  hplot.set_title('Annual Income - Hist Plot',fontsize=14,color='black')
  hplot.set_xlabel('Annual Income',fontsize=14,color='b')
  hplot.set_ylabel('Count',fontsize=14,color='b')

draw_annual_income_plots()
# inference 
# - distribution of annual income of applicants.
# - there are few outliers

"""Remove outliers in annual income"""

loan = loan[loan["annual_inc"] < loan["annual_inc"].quantile(0.99)]
print('after removing outliers')
loan['annual_inc'].describe()

draw_annual_income_plots()
# inference
# - outliers are removed, which helps with data distribution. 
# - median is 58000

"""Univariate Analysis on chargeoff_within_12_mths and collection_recovery_fee - Quantitative Variables"""

loan['chargeoff_within_12_mths'].unique()
# has only zeroes-> add 'chargeoff_within_12_mths' to list of columns to be removed
columns_list_remove.add('chargeoff_within_12_mths')
# loan['collection_recovery_fee'].unique()
draw_custom_hist_plot(loan,'collection_recovery_fee','Collection Recovery Fee','Count')

# inference -> most collection recovery fee is under 3500

"""Univariate analysis on collections_12_mths_ex_med and delinq_2yrs - Quantitative Variables

delinq_2yrs: The past-due amount owed for the accounts on which the borrower is now delinquent.
"""

loan['collections_12_mths_ex_med'].unique()
# has only zeroes-> add 'collections_12_mths_ex_med' to list of columns to be removed
columns_list_remove.add('collections_12_mths_ex_med')
draw_custom_hist_plot(loan,'delinq_2yrs','Delinq 2 years','Count')

# Inference
# - atleast 35000 applications have deliquent borrowers

"""Univariate Analysis on delinq_amnt and dti - Quantitative Variables

dti: A ratio calculated using the borrower’s total monthly debt payments on the total debt obligations, excluding mortgage and the requested LC loan, divided by the borrower’s self-reported monthly income.
"""

loan['delinq_amnt'].unique()
# has only zeroes-> add 'delinq_amnt' to list of columns to be removed
columns_list_remove.add('delinq_amnt')
draw_custom_hist_plot(loan,'dti','DTI','Count')

# Inference 
# - distribution of dti among applications

"""Univariate analysis on derived column earliest_cr_line_year - Derived Ordered Categorical variable"""

# earliest_cr_line -> The year the borrower's earliest reported credit line was opened
draw_custom_hist_plot(loan,'earliest_cr_line_year','Earliest CR Line Year','Count')

# inference
# - most credit lines were opened in 2000

"""Univariate Analysis on Emp Length - Ordered Categorical Variable"""

draw_custom_hist_plot(loan,'emp_length','Employee Experience (Years)','Count')

# inference 
# - most loan applications have applicants with more than 10 years of work experience

"""Univariate analysis on Funded Amount - Quantitative Variable"""

# funded_amnt
print(loan['funded_amnt'].describe())

plt.figure(figsize=(15,10),facecolor='lightblue')
plt.subplot(2, 2, 1)
bplot = sns.boxplot(y=loan['funded_amnt'])
bplot.ticklabel_format(style='plain', axis='y')
bplot.set_title('Funded Amount - Box Plot',fontsize=14,color='black')
bplot.set_ylabel('Funded Amount',fontsize=14,color='b')
plt.subplot(2, 2, 2)
# draw_custom_hist_plot(loan,'funded_amnt','Funded Amount','Count')
hplot = sns.histplot(loan['funded_amnt'])
hplot.ticklabel_format(style='plain', axis='x')
hplot.set_title('Funded Amount - Hist Plot',fontsize=14,color='black')
hplot.set_xlabel('Funded Amount',fontsize=14,color='b')


# Inference 
# - distribution of funded amount
# - median value is 9600
# - most applications have 11000

"""Univariate Analysis on Funded Amount Invested - Quantitative Variable"""

# funded_amnt_inv
print(loan['funded_amnt_inv'].describe())

plt.figure(figsize=(15,10),facecolor='lightblue')
plt.subplot(2, 2, 1)
bplot = sns.boxplot(y=loan['funded_amnt_inv'])
bplot.ticklabel_format(style='plain', axis='y')
bplot.set_title('Funded Amount Invested - Box Plot',fontsize=14,color='black')
bplot.set_ylabel('Funded Amount Invested',fontsize=14,color='b')
plt.subplot(2, 2, 2)
# hplot = draw_custom_hist_plot(loan,'funded_amnt_inv','Funded Amount Invested ','Count')
hplot = sns.histplot(loan['funded_amnt_inv'])
hplot.ticklabel_format(style='plain', axis='x')
hplot.set_title('Funded Amount Invested - Hist Plot',fontsize=14,color='black')
hplot.set_xlabel('Funded Amount Invested',fontsize=14,color='b')
hplot.set_ylabel('Count',fontsize=14,color='b')

# Inference 
# - distribution of funded amount Invested
# - median value is 8975
# - there are outliers

"""Univariate analysis on Grade - Ordered Categorical Variable"""

# grade -> LC assigned loan grade
draw_custom_hist_plot(loan,'grade','Loan Grade','Count')

# Inference
# - most number of applications have B grade

"""Univariate analysis on home_ownership - Categorical Variable"""

draw_custom_hist_plot(loan,'home_ownership','Home Ownership','Count')

# Inference
# - most number of applications have rented house

"""Univariate analysis on Int Rate - Quantitative variable"""

print(loan['int_rate'].describe())

plt.figure(figsize=(15,10),facecolor='lightblue')
plt.subplot(2, 2, 1)
bplot = sns.boxplot(y=loan['int_rate'])
bplot.ticklabel_format(style='plain', axis='y')
bplot.set_title('Interest Rate - Box Plot',fontsize=14,color='black')
bplot.set_ylabel('Interest Rate',fontsize=14,color='b')
plt.subplot(2, 2, 2)
# draw_custom_hist_plot(loan,'int_rate','Interest Rate','Count')
hplot = sns.histplot(loan['int_rate'])
hplot.ticklabel_format(style='plain', axis='x')
hplot.set_title('Interest Rate - Hist Plot',fontsize=14,color='black')
hplot.set_xlabel('Interest Rate',fontsize=14,color='b')
hplot.set_ylabel('Count',fontsize=14,color='b')
# Inference
# - most number of applications have 7.5 interest rate

"""Univariate analysis on Loan Amount - Quantitative variable"""

loan['loan_amnt'].describe()

plt.figure(figsize=(15,10),facecolor='lightblue')
plt.subplot(2, 2, 1)
bplot = sns.boxplot(y=loan['loan_amnt'])
bplot.ticklabel_format(style='plain', axis='y')
bplot.set_title('Loan Amount - Box Plot',fontsize=14,color='black')
bplot.set_ylabel('Loan Amount',fontsize=14,color='b')
plt.subplot(2, 2, 2)
# draw_custom_hist_plot(loan,'loan_amnt','Loan Amount','Count')
hplot = sns.histplot(loan['loan_amnt'])
hplot.ticklabel_format(style='plain', axis='x')
hplot.set_title('Loan Amount - Hist Plot',fontsize=14,color='black')
hplot.set_xlabel('Loan Amount',fontsize=14,color='b')

# Inference 
# - distribution of loan amount
# - median value is 10000
# - Most applications have requested for 11000

"""Univariate analysis on Loan Status - Ordered Categorical variable"""

draw_custom_hist_plot(loan,'loan_status','Loan Status','Count')

# Inference 
# - Most loans are fully paid
# - Can calculate the % of charged off loans

"""Univariate Analysis on Public record of Bankruptcies - Quantitative variable"""

plt.figure(figsize=(15,10),facecolor='lightblue')
hplot = sns.countplot(x=loan['pub_rec_bankruptcies'])
hplot.set_title('Bankruptcies - Count Plot',fontsize=14,color='black')
hplot.set_xlabel('Bankruptcies Count',fontsize=14,color='b')
hplot.set_ylabel('Count',fontsize=14,color='b')
# hplot.bar_label(hplot.containers[0])

# Inference 
# - Most loan applicants dont have public record of bankruptcy
# - 1674 applications have bankruptcy record.
# - 7 have 2 bankruptcies.

"""Univariate Analysis on column Purpose - Unordered categorical variable"""

plt.figure(figsize=(15,10),facecolor='lightblue')
plt.xticks(rotation=90)
hplot = sns.countplot(x=loan['purpose'])
# hplot.bar_label(hplot.containers[0])
hplot.set_title('Purpose - Count Plot',fontsize=14,color='black')
hplot.set_xlabel('Purpose',fontsize=14,color='b')
hplot.set_ylabel('Count',fontsize=14,color='b')
hplot.figure.savefig('purpose-count.png')
# Inference 
# - Most loan applications are for debt consolidation.

print(columns_list_remove)
# drop columns that doesn't have any useful information.
loan.drop(labels = columns_list_remove, axis =1, inplace=True)
# columns reduced to 48
print(loan.shape)

"""Segmented Univariate Analysis

- Mean Loan Amount Invested vs Purpose
"""

# groupby purpose and find mean
def draw_custom_bar_plot(x,y,xlabel,ylabel,x_rot=0):
  plt.figure(figsize=(15,10),facecolor='lightblue')
  plt.xticks(rotation=x_rot)
  hplot = sns.barplot(x=x, y=y)
  # hplot.bar_label(hplot.containers[0])
  hplot.set_title(f'{xlabel} vs {ylabel} - Bar Plot',fontsize=14,color='black')
  hplot.set_xlabel(xlabel,fontsize=14,color='b')
  hplot.set_ylabel(ylabel,fontsize=14,color='b')
  # hplot.bar_label(hplot.containers[0])
  hplot.figure.savefig(f'{xlabel.replace(" ","")}.png')
mean_amount_grouped_by_purpose = loan.groupby('purpose')['funded_amnt_inv'].mean()
draw_custom_bar_plot(mean_amount_grouped_by_purpose.index,mean_amount_grouped_by_purpose.values,'Purpose','Mean Loan Amount Invested',90)

# inference
# - Mean amount is high for house, debt_consolidation and small_business

"""- Median Loan Amount Invested vs Grade"""

# groupby grade and find median
median_amount_grouped_by_grade = loan.groupby('grade')['funded_amnt_inv'].median()
draw_custom_bar_plot(median_amount_grouped_by_grade.index,median_amount_grouped_by_grade.values,'Grade','Median Loan Amount Invested')

# Inference
# - Median amount is high for Grade G loans.
# - Considering Grade G is poor quality loans, the lending club is risking by investing a higher amount of money in risky loans.

"""- Median Loan amount invested vs Home ownership"""

# groupby home ownership and find median
median_amount_grouped_by_home = loan.groupby('home_ownership')['funded_amnt_inv'].median()
draw_custom_bar_plot(median_amount_grouped_by_home.index,median_amount_grouped_by_home.values,'Home Ownership','Median Loan Amount Invested')

# Inference
# - Median amount is high for applicants with Mortgaged loans

"""**Bivariate Analysis**

Loan Amount vs Funded Amount Invested

Funded Amount vs Funded Amount Invested
"""

plt.figure(figsize=(15,10),facecolor='lightblue')
plt.subplot(2, 2, 1)
hplot = sns.scatterplot(x=loan['loan_amnt'],y=loan['funded_amnt_inv'])
hplot.set_title('Loan Amount vs Amount Invested - Scatter Plot',fontsize=14,color='black')
hplot.set_xlabel('Loan Amount',fontsize=14,color='b')
hplot.set_ylabel('Amount Invested',fontsize=14,color='b')
plt.subplot(2, 2, 2)
hplot = sns.scatterplot(x=loan['funded_amnt'],y=loan['funded_amnt_inv'])
hplot.set_title('Funded Amount vs Amount Invested - Scatter Plot',fontsize=14,color='black')
hplot.set_xlabel('Funded Amount (Recommended)',fontsize=14,color='b')
hplot.set_ylabel('Amount Invested',fontsize=14,color='b')

# Inference
# - Amount invested is less than or equal to loan amount requested, never greater.
# - Not always guaranteed to get the requested loan amount.
# - Amount invested is less than or equal to Funded amount recommended by lending club, never greater.
# - Not always guaranteed to get the recommended loan amount by lending club.

"""Term vs Int Rate"""

plt.figure(figsize=(15,10),facecolor='lightblue')

hplot = sns.boxplot(x=loan['term'],y=loan['int_rate'])
hplot.set_title('Term vs Interest Rate - Box Plot',fontsize=14,color='black')
hplot.set_xlabel('Term',fontsize=14,color='b')
hplot.set_ylabel('Interest Rate',fontsize=14,color='b')

# Inference
# - Interest rate is higher if the term is longer.

"""Purpose vs Int Rate"""

plt.figure(figsize=(15,10),facecolor='lightblue')
plt.xticks(rotation=90)
hplot = sns.boxplot(x=loan['purpose'],y=loan['int_rate'])
hplot.set_title('Purpose vs Interest Rate - Box Plot',fontsize=14,color='black')
hplot.set_xlabel('Purpose',fontsize=14,color='b')
hplot.set_ylabel('Interest Rate',fontsize=14,color='b')

# Inference
# - Interest rate is higher for small business and debt_consolidation.

"""State vs Loan Status"""

# Group by status and count the loan per status
# convert it to a dataframe to plot
plt.figure(figsize=(15,10),facecolor='lightblue')
state_groupedby_status = loan.groupby('addr_state').apply(lambda x: x['loan_status'].value_counts())
state_groupedby_status = state_groupedby_status.to_frame('state_groupedby_status').reset_index()
state_groupedby_status = state_groupedby_status.rename(columns={"addr_state":"State","state_groupedby_status": "Count", "level_1": "Status"})
state_groupedby_status

plt.figure(figsize=(15,10),facecolor='lightblue')
hplot = sns.barplot(data = state_groupedby_status, x = "State",y="Count",hue='Status')
hplot.set_xticklabels(
    hplot.get_xticklabels(), 
    rotation=90, 
    horizontalalignment='center',
    fontweight='light',
    fontsize='x-large'

)
# hplot.bar_label(hplot.containers[0])
hplot.set_title('Loan Status Grouped by State - Bar Plot',fontsize=14,color='black')
hplot.set_xlabel('State',fontsize=14,color='b')
hplot.set_ylabel('Count',fontsize=14,color='b')

# Inferences
# - CA has the highest number of loans in each different statuses

"""Grade vs Int Rate"""

plt.figure(figsize=(15,10),facecolor='lightblue')
hplot = sns.boxplot(x=loan['grade'],y=loan['int_rate'],order = 'ABCDEFG')
hplot.set_title('Grade vs Interest Rate - Box Plot',fontsize=14,color='black')
hplot.set_xlabel('Grade',fontsize=14,color='b')
hplot.set_ylabel('Interest Rate',fontsize=14,color='b')

# inference
# - Grade A is the best to get a loan with lower interst rate
# - Grade G is the worst.

"""Interest Rate vs Year"""

plt.figure(figsize=(15,10),facecolor='lightblue')
hplot = sns.boxplot(x=loan['issue_d_year'],y=loan['int_rate'])
hplot.set_title('Year vs Interest Rate - Box Plot',fontsize=14,color='black')
hplot.set_xlabel('Year',fontsize=14,color='b')
hplot.set_ylabel('Interest Rate',fontsize=14,color='b')

# Inference
# - Interest rate increases with the year.
# - The median value of 2010 and 2011 is less than median value of 2009

"""Number of Derogatory Public records V Proportion of Loan Statuses"""

# Group by pub_rec,loan_status and count the loans per status
# convert it to a dataframe to plot
def groupby_dimensions_and_count_values(loan_dataframe, dimension1,dimension2):
  """
  function to group loan df by dimension1 and dimension2
  and count values.
  This function also creates a derived column % which is the % of applications per loan statuses grouped by dimensions.
  """
  df = loan_dataframe.groupby([dimension1,dimension2]).apply(lambda x: x['loan_status'].value_counts())
  df = df.to_frame('df').reset_index()
  df = df.rename(columns={"df": "count", "level_2": "status"})
  # derived column to plot percentage of loan applicants per status grouped by dimension1
  df['%']=(df['count']/df.groupby(dimension1)['count'].transform('sum'))*100
  print(df.head(6))
  return df

def draw_custom_chart(df,x,y,hue,xlabel,ylabel,xrot=0):
  plt.figure(figsize=(15,10),facecolor='lightblue')
  hplot = sns.barplot(data = df, x = x ,y=y ,hue=hue)
  hplot.set_xticklabels(
      hplot.get_xticklabels(), 
      horizontalalignment='center',
      fontweight='light',
      fontsize='x-large',
      rotation=xrot, 

  )
  # hplot.bar_label(hplot.containers[0])
  hplot.set_title(f'% of Loan Status grouped by {xlabel}  - Bar Plot',fontsize=14,color='black')
  hplot.set_xlabel(xlabel,fontsize=14,color='b')
  hplot.set_ylabel(ylabel,fontsize=14,color='b')
  hplot.figure.savefig(f'{xlabel.replace(" ","")}.png')

rec_groupedby_loan_status = groupby_dimensions_and_count_values(loan,'pub_rec','loan_status')

draw_custom_chart(rec_groupedby_loan_status,"pub_rec","%","status","Number of derogatory public records","%")

# Inference
# - No Charged off % for applicants with 3 0r 4 public derogatory records. 
# - Charged off proportion is high for applicants with 1 derogatory record

"""Number of  public records of bankruptcies Vs Proportion of Loan Statuses"""

# Group by pub_rec,loan_status and count the loans per status
# convert it to a dataframe to plot
prec_groupedby_loan_status = groupby_dimensions_and_count_values(loan,'pub_rec_bankruptcies','loan_status')

draw_custom_chart(prec_groupedby_loan_status,"pub_rec_bankruptcies","%","status","Number of Public Bankruptcy Records","%")

# Inference
# - Charged off % is high for those with 2.0 public bankruptcy record
# - Those with 0 bankruptcy record have higher fully paid percentage

"""Purpose Vs Proportion of Loan Statuses"""

# Group by purpose,loan_status and count the loans per status
# convert it to a dataframe to plot
purpose_groupedby_loan_status = groupby_dimensions_and_count_values(loan,'purpose','loan_status')

draw_custom_chart(purpose_groupedby_loan_status,"purpose","%","status","Purpose","%","90")

# Inference
# - Charged off % is higher for small business

"""Grade vs % of Loan Status"""

# Group by grade,loan_status and count the loans per status
# convert it to a dataframe to plot
grade_groupedby_loan_status = groupby_dimensions_and_count_values(loan,'grade','loan_status')

draw_custom_chart(grade_groupedby_loan_status,"grade","%","status","Grade","%")

# Inference
# - Charged off % is higher for Grade G
# - Clearly as the Grade moves from A to G, the charged off proportion increases and fully paid proportion decreases.

"""Employment Length vs  % of Loan Status"""

# Group by emp_length,loan_status and count the loans per status
# convert it to a dataframe to plot
emp_groupedby_loan_status = groupby_dimensions_and_count_values(loan,'emp_length','loan_status')

draw_custom_chart(emp_groupedby_loan_status,"emp_length","%","status","Work Experience","%")

# Inference
# - Charged off % is higher for applicants with 0-1 years of experience.
# - Charged off proportion is almost same for 2 -6 years of experience.

"""Sub Grade vs Loan Status"""

# Group by subgrade,loan_status and count the loans per status
# convert it to a dataframe to plot
totalacc_groupedby_loan_status = groupby_dimensions_and_count_values(loan,'sub_grade','loan_status')

draw_custom_chart(totalacc_groupedby_loan_status,"sub_grade","%","status","Sub Grade","%","90")

# Inference
# - Charged off % is higher for Sub Grade F5
# - Clearly as the Sub Grade moves from A1 to G5, the charged off proportion increases and fully paid proportion decreases.

"""Term vs % of Loan status"""

# Group by subgrade,loan_status and count the loans per status
# convert it to a dataframe to plot
term_groupedby_loan_status = groupby_dimensions_and_count_values(loan,'term','loan_status')

draw_custom_chart(term_groupedby_loan_status,"term","%","status","Term","%")

# inference
# - charged off proprtion is higher for loan with longer term

"""Income Verification Status vs % of Loan status"""

# Group by verification_status,loan_status and count the loans per status
# convert it to a dataframe to plot
ver_groupedby_loan_status = groupby_dimensions_and_count_values(loan,'verification_status','loan_status')

draw_custom_chart(ver_groupedby_loan_status,"verification_status","%","status","Income Verification Status","%")

# inference
# - Charged off percentage is similar for all the categories of income verification.

"""Annual Income Category vs % of Loan Status"""

# Group by annual_inc_cat,loan_status and count the loans per status
# convert it to a dataframe to plot
annual_inc_groupedby_loan_status = groupby_dimensions_and_count_values(loan,'annual_inc_cat','loan_status')

draw_custom_chart(annual_inc_groupedby_loan_status,"annual_inc_cat","%","status","Annual Income (Categorised)","%")

# inference
# - Charged off percentage is higher for loan applicants in annual income category 0-20000.
# - Charged off percentage decreases as the annual income increases.

"""Loan Amount (Categorised) vs % of Loan status"""

# Group by loan_amnt_cat,loan_status and count the loans per status
# convert it to a dataframe to plot
loan_amnt_groupedby_loan_status = groupby_dimensions_and_count_values(loan,'loan_amnt_cat','loan_status')

draw_custom_chart(loan_amnt_groupedby_loan_status,"loan_amnt_cat","%","status","Loan Amount (Categorised)","%")

# inference
# - Charged off percentage is higher for higher loan amount.
# - Fully paid percentage decreases as the loan amount increases.

"""Interest Rate (Categorsied) vs % of Loan Status"""

# Group by int_rate_cat,loan_status and count the loans per status
# convert it to a dataframe to plot
int_rate_groupedby_loan_status = groupby_dimensions_and_count_values(loan,'int_rate_cat','loan_status')

draw_custom_chart(int_rate_groupedby_loan_status,"int_rate_cat","%","status","Interest Rate (Categorised)","%")

# inference
# - Charged off percentage increases as the interest rate increases.

"""Revolving Line Utilisation Rate vs % of Loan Status"""

# Group by int_rate_cat,loan_status and count the loans per status
# convert it to a dataframe to plot
revol_rate_groupedby_loan_status = groupby_dimensions_and_count_values(loan,'revol_util_cat','loan_status')

draw_custom_chart(revol_rate_groupedby_loan_status,"revol_util_cat","%","status","Revolving Line Utilisation Rate (Categorised)","%")

# inference
# - Charged off percentage increases as the revolving line utilisation rate increases.

"""Number of Open Credit Lines (Categorised) vs % of Loan status"""

# Group by int_rate_cat,loan_status and count the loans per status
# convert it to a dataframe to plot
open_acc_groupedby_loan_status = groupby_dimensions_and_count_values(loan,'open_acc_cat','loan_status')

draw_custom_chart(open_acc_groupedby_loan_status,"open_acc_cat","%","status","Number of Credit Lines (Categorised)","%")

# inference
# - Charged off percentage increases as the number of open credit lines increases.

"""Multivariate Analysis"""

# create a df with only important columns
loan_copy = loan[['loan_amnt','funded_amnt','funded_amnt_inv','annual_inc', 'issue_d_year','int_rate','loan_status','pub_rec','dti','pub_rec_bankruptcies']].copy()
loan_copy.head(6)

# draw a heat map for correlation matrix
plt.figure(figsize=(15,10),facecolor='lightblue')
hplot = sns.heatmap(loan_copy.corr(),annot=True)
hplot.set_title('Correlation matrix',fontsize=14,color='black')
hplot.figure.savefig('corr.png')
# inference

# - There is a clear correlation between funded_amnt, loan_amount and loan_amount_inv.
# - There is a correlation between annual income and loan_amount.
# - There is a correlation between int rate and loan_amount.
# - There is negative correlation between number of public derogatory records and loan_amount.
# - There is negative correlation between dti and annual_inc.